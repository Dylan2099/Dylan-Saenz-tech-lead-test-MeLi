# ðŸŽ® MeLi Arcade: AI-Powered Trivia Agent

![App Preview](./assets/app_preview_v2.png)

> **ðŸ”´ Live Demo:** [Haz clic aquÃ­ para jugar](https://meli-frontend-856233821367.us-central1.run.app)

Este mÃ³dulo implementa un sistema interactivo de trivia utilizando **Agentes de IA Generativa** orquestados con grafos de estado. La soluciÃ³n estÃ¡ diseÃ±ada bajo una arquitectura de microservicios desacoplada, separando la lÃ³gica de negocio (Backend) de la interfaz de usuario (Frontend).

## ðŸ— Arquitectura del Sistema

El sistema consta de dos servicios contenerizados que se comunican vÃ­a HTTP:

1.  **Backend (Brain):** API REST construida con **FastAPI**.
    *   OrquestaciÃ³n: **LangGraph** (Stateful Multi-Agent).
    *   IA: **Vertex AI (Gemini 2.5 Flash)**.
    *   Persistencia: **SQLModel** (SQLite) para sesiones y ranking.
2.  **Frontend (Face):** Interfaz interactiva construida con **Streamlit**.
    *   GamificaciÃ³n: Animaciones Lottie y sistema de feedback visual.
    *   ComunicaciÃ³n: Cliente HTTP que consume la API del backend.

---

## âš™ï¸ ConfiguraciÃ³n Previa (Crucial)

Antes de ejecutar, es necesario configurar las credenciales y variables de entorno.

1.  **Google Cloud Platform:**
    *   AsegÃºrate de tener un proyecto en GCP con la API de **Vertex AI** habilitada.
    *   Debes tener configurada la autenticaciÃ³n local (si corres en local) o montar las credenciales en Docker (si aplica).

2.  **Variables de Entorno (.env):**
    Crea un archivo llamado `.env` dentro de la carpeta `ejercicio_2/`. Copia el siguiente contenido y reemplaza con tus datos:

    ```env
    # ID de tu proyecto en Google Cloud
    PROJECT_ID=tu-id-de-proyecto-real
    
    # RegiÃ³n de despliegue (ej. us-central1)
    REGION=us-central1
    
    # Modelo a utilizar
    MODEL_NAME=gemini-2.5-flash
    
    # ConfiguraciÃ³n del Juego
    MAX_QUESTIONS=3
    TRIVIA_TOPIC="Google Cloud Platform"
    
    # Networking
    # - Docker/Cloud: API_URL=http://backend:8000 (o URL real)
    # - Local Python: API_URL=http://127.0.0.1:8000
    API_URL=http://backend:8000
    ```

---

## ðŸš€ EjecuciÃ³n con Docker (Local)

La forma mÃ¡s sencilla de probar el sistema localmente es utilizando Docker Compose.

1.  Construye y levanta los servicios:
    ```bash
    cd ejercicio_2
    docker-compose up --build
    ```

2.  Accede a la aplicaciÃ³n:
    *   **Frontend (Juego):** [http://localhost:8501](http://localhost:8501)
    *   **Backend (Docs API):** [http://localhost:8000/docs](http://localhost:8000/docs)

> **Nota:** La base de datos SQLite persistirÃ¡ en la carpeta `./data` de tu mÃ¡quina local gracias al volumen configurado.

---

## â˜ï¸ Despliegue en Google Cloud Run

Para llevar esta arquitectura a producciÃ³n en un entorno Serverless:

### 1. PreparaciÃ³n
AsegÃºrate de tener `gcloud` CLI instalado y autenticado.
```bash
gcloud auth login
gcloud config set project TU_PROJECT_ID
```

### 2. Crear Repositorio de Artefactos
```bash
gcloud artifacts repositories create meli-repo --repository-format=docker --location=us-central1
```

### 3. Desplegar Backend (API)
```bash
# Construir imagen
gcloud builds submit --tag us-central1-docker.pkg.dev/TU_PROJECT_ID/meli-repo/backend:v1 .

# Desplegar servicio
gcloud run deploy meli-backend \
  --image us-central1-docker.pkg.dev/TU_PROJECT_ID/meli-repo/backend:v1 \
  --region us-central1 \
  --platform managed \
  --allow-unauthenticated \
  --port 8000 \
  --set-env-vars "PROJECT_ID=TU_PROJECT_ID,REGION=us-central1,MAX_QUESTIONS=3,TRIVIA_TOPIC=Google Cloud"
```
*Copia la URL generada (ej: `https://meli-backend-xyz.a.run.app`).*

### 4. Desplegar Frontend (UI)
```bash
# Construir imagen (reutilizamos el mismo Dockerfile inteligente)
gcloud builds submit --tag us-central1-docker.pkg.dev/TU_PROJECT_ID/meli-repo/frontend:v1 .

# Desplegar conectando con el Backend
gcloud run deploy meli-frontend \
  --image us-central1-docker.pkg.dev/TU_PROJECT_ID/meli-repo/frontend:v1 \
  --region us-central1 \
  --platform managed \
  --allow-unauthenticated \
  --port 8501 \
  --set-env-vars "API_URL=TU_URL_DEL_BACKEND" \
  --command="streamlit" \
  --args="run,src/frontend.py,--server.port=8501,--server.address=0.0.0.0"
```

> **ConsideraciÃ³n de Arquitectura:** En Cloud Run, el sistema de archivos es efÃ­mero. La base de datos SQLite se reiniciarÃ¡ con cada nuevo despliegue. Para persistencia real en producciÃ³n, se recomienda conectar el servicio a **Google Cloud SQL**.

---

## ðŸ“‚ Estructura de Archivos

```text
ejercicio_2/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents.py      # LÃ³gica de LangGraph (Nodos y Flujo)
â”‚   â”œâ”€â”€ api.py         # Endpoints FastAPI
â”‚   â”œâ”€â”€ frontend.py    # UI Streamlit
â”‚   â”œâ”€â”€ models.py      # Esquema de Base de Datos (SQLModel)
â”‚   â”œâ”€â”€ state.py       # DefiniciÃ³n del Estado del Grafo
â”‚   â””â”€â”€ config.py      # GestiÃ³n de configuraciÃ³n
â”œâ”€â”€ data/              # Almacenamiento persistente (SQLite)
â”œâ”€â”€ Dockerfile         # DefiniciÃ³n de imagen unificada
â”œâ”€â”€ docker-compose.yml # OrquestaciÃ³n de servicios
â””â”€â”€ requirements.txt   # Dependencias del proyecto
```

---
**Tech Stack:** Python 3.11, LangGraph, Vertex AI, FastAPI, Streamlit, Docker, Cloud Run.
